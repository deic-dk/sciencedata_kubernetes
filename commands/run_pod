#!/bin/bash

# run_pod -o owner -k public_key -r nfs_storage_path -l local_storage_path yaml_file
# Notice that the mount point for the nfs and/or local volume must be specified in the yaml file.
# E.g.
# run_pod -o fror@dtu.dk  -k "`cat ~/.ssh/id_rsa.pub`" -r www /root/sciencedata_kubernetes/pod_manifests/ubuntu_sciencedata.yaml
# run_pod -o fror@dtu.dk -l /usr/local/software -p 8888 /root/sciencedata_kubernetes/pod_manifests/jupyter_sciencedata.yaml

logfile='/var/log/kube.log'
# If you have more than one public IP, you may need to hardcode EXTERNAL_IP
EXTERNAL_IP=`hostname -I | sed "s| |\n|g" |  grep -E -v '^(192\.168|10\.|172\.1[6789]\.|172\.2[0-9]\.|172\.3[01]\.)' | head -1`
# ScienceData internal IP. This presumes you've made an entry for sciencedata in /etc/hosts -if not, just hardcode SCIENCEDATA_IP
SCIENCEDATA_IP=`grep -E '\ssciencedata$' /etc/hosts | sed -E 's|^([0-9\.]+)\s.*|\1|'`
if [ -z "$SCIENCEDATA_IP" ]; then
	SCIENCEDATA_IP=10.0.0.13
fi
# This is the trusted, not for users, internal network
SCIENCEDATA_INTERNAL_NET=10.0.
# This is private user network (of the vlan interface)
SCIENCEDATA_PRIVATE_NET=10.2.
# Fallback public DNS name for sciencedata server/silo of the user in question (currently used only for the Caddy web page).
SCIENCEDATA_PUBLIC_IP=sciencedata.dk

cmd="`echo $(readlink -f \"$0\")`"
DIR="`dirname $cmd`"

SSH_SERVICE_YAML_FILE="$DIR/../service_manifests/ssh_service.yaml"
NFS_VOLUME_YAML_FILE="$DIR/../service_manifests/nfs_volume.yaml"
NFS_CLAIM_YAML_FILE="$DIR/../service_manifests/nfs_claim.yaml"
LOCAl_VOLUME_YAML_FILE="$DIR/../service_manifests/local_volume.yaml"
LOCAL_CLAIM_YAML_FILE="$DIR/../service_manifests/local_claim.yaml"
CADDY_FILE="$DIR/../service_manifests/Caddyfile"
TMPDIR="/tmp"

yaml_file=""
owner=""
ssh_public_key=""
nfs_storage_path=""
dryrun=

#### Define slow functions to run in background after successful pod creation
start_reverse_proxy() {
    # Wait for one minute for pod to start
    for i in {1..6}; do
        # Find local IP
        pod_ip=$(kubectl get pod "$pod_name" -o json | jq -r '.status.podIP' | sed 's|null||')
        if [[ -n "$pod_ip" ]]; then
            rm ${TMPDIR}/uri-${pod_name} 2>&1 >> "$logfile"
            echo "INFO: Running reverse proxy caddy reverse-proxy --from https://kube.sciencedata.dk:$reverse_proxy_port --to ${pod_ip}:${pod_http_port}" >> "$logfile"
            caddyfile="$TMPDIR/Caddyfile-${pod_ip}-${reverse_proxy_port}-${pod_name}"
            sed "s|WEBPORT|$reverse_proxy_port|" "$CADDY_FILE" > "$caddyfile"
            sed -i "s|PODIP|$pod_ip|" "$caddyfile"
            sed -i "s|PODPORT|$pod_http_port|" "$caddyfile"
            export PATH=/bin/:/usr/bin:/usr/local/bin
            caddy run --adapter caddyfile --config "$caddyfile" &>> "${caddyfile}.log" &
            kubectl exec --stdin ${pod_name} -- cat /tmp/URI 2>>"$logfile" > ${TMPDIR}/uri-${pod_name}
            break
        fi
        sleep 10
    done
    if [[ -z "$pod_ip" ]]; then
        echo "ERROR: pod $pod_name did not start. NOT running reverse proxy caddy reverse-proxy --from https://kube.sciencedata.dk:$reverse_proxy_port --to ${pod_ip}:${pod_http_port}." >> "$logfile"
        exit 1
    else
        # Now wait in the background for another 5 minutes for any /tmp/URI to pop up in the container
        ( for i in {1..60}; do
              # If there's a file /tmp/URI, copy it out to /var/run/sciencedata/uri-${pod_name}
              sleep 5
              kubectl exec --stdin ${pod_name} -- cat /tmp/URI 2>>"$logfile" > ${TMPDIR}/uri-${pod_name}
              [[ -e ${TMPDIR}/uri-${pod_name} ]] && [[ ! -s ${TMPDIR}/uri-${pod_name} ]] && rm ${TMPDIR}/uri-${pod_name}
              [[ -s ${TMPDIR}/uri-${pod_name} ]] && break
          done ) 2>&1 >> "$logfile"
    fi
}

while getopts "o:s:k:r:l:p:d" flag; do
	case "$flag" in
		o)
			# ScienceData userid who will own the pod
			owner=$OPTARG
			;;
		s)
			# Optional ScienceData home server of the userid who will own the pod
			# Only necessary for local-only users
			home_server=$OPTARG
			;;
		k)
			# Public key to be inserted into /root/.ssh/authorized_keys
			ssh_public_key=$OPTARG
			;;
		r)
			# Path on home server to be claimed, relative to /tank/storage/owner/
			# Notice that the mountpoint is specified in the pod yaml
			nfs_storage_path=$OPTARG
			;;
		l)
			# Path on local server to be claimed - absolute.
			# Notice that the mountpoint is specified in the pod yaml
			local_storage_path=$OPTARG
			;;
		p)
			# Port of web server running in the pod, i.e.
			# the port that will be proxied to
			pod_http_port=$OPTARG
			;;
		d)
			# If set, no actions are performed, only reported
			dryrun="yes"
			;;
		\?)
			echo "Invalid option: -$OPTARG" >&2
			exit 1
			;;
		:)
			echo "Option -$OPTARG requires an argument." >&2
			exit 1
			;;
	esac
done

yaml_file=${@:$OPTIND:1}
#EXTRA_ARG=${@:$OPTIND+1:1}

if [ -z "$yaml_file" ]; then
	echo "ERROR: Need input file" >&2
	exit 1
fi

if [ ! -f "$yaml_file" ]; then
	echo "ERROR: Input file $yaml_file not found" >&2
	exit 1
fi

if [ ! -s "$yaml_file" ]; then
	echo "ERROR: Input file is empty" >&2
	exit 1
fi

if [ -z "$owner" ]; then
	echo "ERROR: Need owner"  >&2
	exit -1
fi

# Check if the user is attempting to use the host network
grep -iE 'hostnetwork' "$yaml_file"
if [ $? -eq 0 ]; then
	echo "ERROR: Only internal network allowed" >&2
	exit -2
fi

# Check if the user is attempting an NFS volume deployment (mount)
grep -iE 'kind: *Deployment' "$yaml_file"
if [ $? -eq 0 ]; then
	echo "ERROR: Manual mounts are not allowed" >&2
	exit -2
fi

# Check if there is a persistentVolumeClaim claim in the pod yaml
grep -E '^ claimName:' "$yaml_file"
if [ "$?" -eq "0" ]; then
	echo "ERROR: Manual claims are not allowed" >&2
	exit -3
fi

if [ -z "$ssh_public_key" ]; then
	# No ssh public key given on stdin, try getting it from env
	ssh_public_key="$SSH_PUBLIC_KEY"
	if [ -z "$ssh_public_key" ]; then
		# Try getting ssh public key from yaml
		ssh_public_key="`cat \"$yaml_file\" | yq -r '.spec.containers[]?.env[]? | select(.name == \"SSH_PUBLIC_KEY\") | .value'`"
		if [ -z "$ssh_public_key" ]; then
			echo "WARNING: No SSH public key - it will not be possible to log in" >> "$logfile"
		fi
	fi
fi

if [ -z "$local_storage_path" ]; then
	# No local storage path given on stdin, try getting it from env
	local_storage_path="$LOCAL_STORAGE_PATH"
	if [ -z "$local_storage_path" ]; then
		# Try getting local storage path from yaml
		local_storage_path="`cat \"$yaml_file\" | yq -r '.spec.containers[]?.env[]? | select(.name == \"MOUNT_SRC\") | .value'`"
	fi
fi

if [ -z "$pod_http_port" ]; then
	# No HTTP port given on stdin, try getting it from env
	pod_http_port="$POD_HTTP_PORT"
	if [ -z "$pod_http_port" ]; then
		# Try getting POD HTTP port from yaml
		pod_http_port="`cat \"$yaml_file\" | yq -r '.spec.containers[]?.env[]? | select(.name == \"POD_HTTP_PORT\") | .value'`"
		# If port 80 is exposed, we assume it's a web server
		if [ -z "$pod_http_port" ]; then
			pod_http_port="`cat \"$yaml_file\" | yq -r '.spec.containers[]?.ports[]? | select(.containerPort == 80 and .protocol == \"TCP\") | .containerPort'`"
		fi
	fi
fi


user=`echo $owner | awk -F@ '{print $1}'`
domain=`echo $owner | awk -F@ '{print $2}'`
owner_str=`echo $owner | sed 's|[@._]|-|g'`

pod_name="`cat \"$yaml_file\" | yq -r .metadata.name | head -1`-${owner_str}"

# Try up to 9 times to append to name if pod with this name is already running (i.service/jupyter-fror-dtu-dk-ssh. allow 10 copies per user)
new_pod_name="${pod_name}"
for i in {1..9}; do
	kubectl get pod "$new_pod_name" >& /dev/null
	if [ $? -eq 0 ]; then
		new_pod_name="${pod_name}-${i}"
	else
		break
	fi
done
if [ -n "$new_pod_name" ] && [ "$new_pod_name" != "$pod_name" ]; then
	pod_name="$new_pod_name"
fi

# Check if $owner has a public home server configured, otherwise set to $SCIENCEDATA_PUBLIC_IP
public_home_server=`curl --insecure "https://${SCIENCEDATA_IP}/apps/files_sharding/ws/get_user_server.php?user_id=${owner}&internal=no" | sed 's|\\/|/|g' | jq -r '.url' | grep -E 'https*://' | sed -E 's|^https*://||' 2> "$logfile"`
echo "Home server: $public_home_server" >> "$logfile"
if [ -z "$public_home_server" ]; then
	public_home_server=$SCIENCEDATA_PUBLIC_IP
fi

# Check if home_server is set, otherwise check if $owner has a home server configured, finally to $SCIENCEDATA_IP
if [ -z $home_server ]; then
	home_server=`curl --insecure "https://${SCIENCEDATA_IP}/apps/files_sharding/ws/get_user_server.php?user_id=${owner}&internal=yes" | sed 's|\\/|/|g' | jq -r '.url' | grep -E 'https*://' | sed -E 's|^https*://||' 2> /dev/null`
fi

if [ -n "$nfs_storage_path" ]; then
	if [ -z $home_server ]; then
		home_server=$SCIENCEDATA_IP
	fi
	# Check if directory exists
	dir_exists_http_code=`curl --insecure -H "Depth: 0" -X PROPFIND -o /dev/null -w "%{http_code}" \
	-u ${owner}: "https://${home_server}/storage/${nfs_storage_path}/" 2> /dev/null`
	# Create if not
	if [ "$dir_exists_http_code" != "207" ] && [ -z "$dryrun" ]; then
		echo "INFO: https://${home_server}/storage/${nfs_storage_path}/ does NOT exist" >> "$logfile"
		dir_create_http_code=$(curl --insecure -X MKCOL -o /dev/null -w "%{http_code}" -u ${owner}: \
                                "https://${home_server}/storage/${nfs_storage_path}/" 2> /dev/null)
    if [[ $dir_create_http_code != 201 ]]; then
      echo "WARNING: Failed to create storage directory" >> "$logfile"
    fi
	fi
  nfs_volume_name="nfs-${home_server}-${owner_str}-$(sed 's|/|-|g' <<< "${nfs_storage_path}")"
  nfs_claim_name=$nfs_volume_name # just use the same name
	if [ $home_server ]; then
		# Check if the volume is already mounted
		kubectl get persistentvolume | grep "^${nfs_volume_name} " >& /dev/null
		if [ "$?" -ne "0" ]; then
			create_nfs_volume="yes"
		else
			kubectl get pv -o yaml | yq '.items[] | (.spec.nfs.server+":"+.spec.nfs.path)' | grep "${home_server}:/tank/storage/${owner_str}/${nfs_storage_path}" >& /dev/null
			if [ "$?" -ne "0" ]; then
				create_nfs_volume="yes"
			fi
		fi
		# Check if a claim has already been made on $nfs_storage_path
		kubectl get persistentvolumeclaim | grep  "^${nfs_claim_name} " >& /dev/null
		if [ "$?" -ne "0" ]; then
			create_nfs_claim="yes"
		fi
	fi
fi

if [ -n "$local_storage_path" ]; then
	local_storage_name=`echo $local_storage_path | sed 's|/|-|g'`
	# Check if directory exists
	if [ -d "$local_storage_path" ]; then
		kubectl get persistentvolume | grep "local-${local_storage_name}" >& /dev/null
		if [ "$?" -ne "0" ]; then
			create_local_volume="yes"
		fi
	fi
	# Check if a claim has already been made on $local_storage_path
	kubectl get PersistentVolumeClaim | grep  "local-claim-${local_storage_name}" >& /dev/null
	if [ "$?" -ne "0" ]; then
		create_local_claim="yes"
	fi
fi

# Find free port for Caddy proxy in range 2000-3000 iff there is a port to forward to
if [[ -n $pod_http_port ]]; then
  for reverse_proxy_port in {2000..3000}; do
  	ps aux | grep "caddy run .*\-\-config ${TMPDIR}/Caddyfile-.*-" >& /dev/null || break
  	ps auxw | grep caddy | grep -v "/etc/caddy/Caddyfile" | grep -v grep | grep -E "caddy run .*\-\-config ${TMPDIR}/Caddyfile-.*-${reverse_proxy_port}" >&/dev/null || break
  done
else
  reverse_proxy_port=''
fi

# This is picked up by start.sh inside the container (for ScienceData-enabled containers)
if [ $home_server ]; then
	export my_home_server=`echo $home_server | sed "s|^$SCIENCEDATA_INTERNAL_NET|$SCIENCEDATA_PRIVATE_NET|"`
fi

cat $yaml_file |\
if [ -n "$pod_name" ]; then
	### Modify pod YAML - ssh public key, metadata, volume. Pass the env variable FILE on.
  modified_yaml=$( cat $yaml_file | \
	yq -r "(.spec.containers[]?.env[]? | select(.name == \"SSH_PUBLIC_KEY\") | .value) |= \"$ssh_public_key\"" | \
	yq -r "(.spec.containers[]?.env[]? | select(.name == \"SD_UID\") | .value) |= \"$owner\"" | \
	yq -r "(.spec.containers[]?.env[]? | select(.name == \"FILE\") | .value) |= \"$FILE\"" | \
	yq -r "(.spec.containers[]?.env[]? | select(.name == \"HOME_SERVER\") | .value) |= \"$my_home_server\"" | \
	yq -r "(.spec.containers[]?.env[]? | select(.name == \"PUBLIC_HOME_SERVER\") | .value) |= \"$public_home_server\"" | \
	sed "s|HOME_SERVER/storage/mathpass|${my_home_server}/storage/mathpass|" | \
	yq -r -y ".metadata.name=\"$pod_name\"" |\
	yq -r -y ".metadata.labels.user=\"$user\"" | \
	yq -r -y ".metadata.labels.domain=\"$domain\"" |\
	yq -r -y ".metadata.labels.app=\"$pod_name\"" | \
	( [ -z "$pod_http_port" ] && cat || yq -r -y ".metadata.labels.reverseProxyPort=\"$reverse_proxy_port\"" ) |\
	( [ -z "$nfs_storage_path" ] && cat || yq -r -y ".spec.volumes|= .+ [{\"name\":\"sciencedata\", \"persistentVolumeClaim\": {\"claimName\": \"${nfs_volume_name}\"}}]") |\
	( [ -z "$local_storage_name" ] && cat || yq -r -y ".spec.volumes|= .+ [{\"name\":\"local\", \"persistentVolumeClaim\": {\"claimName\": \"local-claim-${local_storage_name}\"}}]")
	### SSH service
	if [ -n "$ssh_public_key" ]; then
		echo "---"
		cat "$SSH_SERVICE_YAML_FILE"| yq -r -y ".spec.externalIPs=[\"$EXTERNAL_IP\"]" |\
		yq -r -y ".metadata.name=\"${pod_name}-ssh\"" | yq -r -y ".spec.selector={\"app\":\"$pod_name\"}"
	fi
	if [ -n "$nfs_storage_path" ]; then
		### NFS volume
		if [ -n "$create_nfs_volume" ]; then
			echo "---"
			cat "$NFS_VOLUME_YAML_FILE" | \
			sed "s|NFS_VOLUME_NAME|${nfs_volume_name}|g" | \
			sed "s|STORAGE_PATH|${owner}/${nfs_storage_path}|g" | \
			sed "s|SERVER_IP|$home_server|g"
		fi
		### NFS persistent volume claim
		if [ -n "$create_nfs_claim" ]; then
			echo "---"
			cat "$NFS_CLAIM_YAML_FILE" | \
			sed "s|NFS_VOLUME_NAME|${nfs_volume_name}|g" | \
			sed "s|NFS_CLAIM_NAME|${nfs_claim_name}|g"
		fi
	fi
	if [ -n "$local_storage_name" ]; then
		### Local volume
		if [ -n "$create_local_volume" ]; then
			echo "---"
			cat "$LOCAl_VOLUME_YAML_FILE" | \
			sed "s|LOCAL_VOLUME_NAME|local-${local_storage_name}|g" | \
			sed "s|STORAGE_PATH|${local_storage_path}|g"
		fi
		### Local persistent volume claim
		if [ -n "$create_local_claim" ]; then
			echo "---"
			cat "$LOCAL_CLAIM_YAML_FILE" | \
			sed "s|LOCAL_CLAIM_NAME|local-claim-${local_storage_name}|g"
		fi
	fi
	)

  echo "$modified_yaml" >> "$logfile"
  # Now apply the yaml and save the output of the kubectl command
  if [[ -z "$dryrun" ]]; then
      kubectl_output=$( kubectl apply -f - < <(echo "$modified_yaml") )
  else
      kubectl_output=$( kubectl apply --validate=true --dry-run=client -f - < <(echo "$modified_yaml") )
  fi

  echo "$kubectl_output" >> "$logfile"
  # If it worked, there should be a line in the output like 'pod/jupyter... created'. In that case report success
  regex='.*^pod/[^'$'\n'']+created$.*'
  if [[ $kubectl_output =~ $regex ]]; then
      echo "SUCCESS: $pod_name"
      # begin background processes if required
      if [[ -n "$pod_http_port" ]]; then
          start_reverse_proxy >& /dev/null &
      fi
      exit 0
  else
      echo "FAILURE: kubectl did not create pod"
      exit 1
  fi
else
	echo "ERROR: Parsing .metadata.name from YAML failed" >&2
	exit 2
fi
